{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Paths\n",
    "population_path = Path(\"../Group3Project1/Resources/sub-est2022.csv\")\n",
    "snp500_path = Path(\"../Group3Project1/Resources/constituents.csv\")\n",
    "\n",
    "# Reading CSV\n",
    "population_data = pd.read_csv(population_path, header=0) \n",
    "snp500_data = pd.read_csv(snp500_path, index_col=\"Symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing and Cleaning SUMLEV 162(Cities) Population Data\n",
    "cities_population_data = population_data[population_data[\"SUMLEV\"] == 162]\n",
    "cities_population_data = cities_population_data[['NAME', 'STNAME', 'POPESTIMATE2022']]\n",
    "cities_population_data.columns = ['city', 'state', 'population']\n",
    "cities_population_data['city'] = cities_population_data['city'].str.replace(\n",
    "  r' (City|city|town|village|borough)', '', regex=True)\n",
    "cities_population_data['city'] = cities_population_data['city'].str.replace(r'\\bSt\\. \\b', 'Saint ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing and Cleaning SUMLEV 050(County) Population Data\n",
    "counties_population_data = population_data[population_data[\"SUMLEV\"] == 50]\n",
    "counties_population_data = counties_population_data[['NAME', 'STNAME', 'POPESTIMATE2022']]\n",
    "counties_population_data.columns = ['city', 'state', 'population']\n",
    "\n",
    "counties_population_data['city'] = counties_population_data['city'].str.replace(\n",
    "  r' (city|town|village|County|Parish|Planning Region|Census Area|City and Borough|Borough|Municipality)$',\n",
    "  '', regex=True)\n",
    "counties_population_data['city'] = counties_population_data['city'].str.replace(r'\\bSt\\. \\b', 'Saint ', regex=True)\n",
    "counties_population_data['city'] = counties_population_data['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing and Cleaning SUMLEV 061(Towns) Population Data\n",
    "towns_population_data = population_data[population_data[\"SUMLEV\"] == 61]\n",
    "towns_population_data = towns_population_data[['NAME', 'STNAME', 'POPESTIMATE2022']]\n",
    "towns_population_data.columns = ['city', 'state', 'population']\n",
    "towns_population_data['city'] = towns_population_data['city'].str.replace(\n",
    "  r' (City|city|township|town|village|-Troy Hills)', '', regex=True)\n",
    "towns_population_data['city'] = towns_population_data['city'].str.replace(r'\\bSt\\. \\b', 'Saint ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and preparing Louisville(SUMLEV 157) and Nashville(SUMLEV 172) data\n",
    "targeted_population_data = population_data[population_data[\"SUMLEV\"].isin([157, 172])]\n",
    "targeted_population_data = targeted_population_data[['NAME', 'STNAME', 'POPESTIMATE2022']]\n",
    "targeted_population_data.columns = ['city', 'state', 'population']\n",
    "\n",
    "targeted_population_data['city'] = targeted_population_data['city'].str.replace(\n",
    "  r'(-Davidson metropolitan government \\(balance\\)|/Jefferson County metro government \\(balance\\))', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing and cleaning S&P500 Data\n",
    "split_locations = snp500_data['Headquarters Location'].str.split(',', expand=True)\n",
    "snp500_data['city'] = split_locations[0]\n",
    "snp500_data['state'] = split_locations[1] if split_locations.shape[1] > 1 else None\n",
    "\n",
    "snp500_data['city'] = snp500_data['city'].str.strip()\n",
    "snp500_data['state'] = snp500_data['state'].str.strip() if snp500_data['state'] is not None else None\n",
    "snp500_data['city'] = snp500_data['city'].str.replace(r' (City|County|Village|Ranch)$', '', regex=True)\n",
    "snp500_data['city'] = snp500_data['city'].str.replace(r'\\bSt\\. \\b', 'Saint ', regex=True)\n",
    "if 'state' in snp500_data.columns:\n",
    "  snp500_data['state'] = snp500_data['state'].str.replace(r'\\bD.C\\.', 'District of Columbia', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intial Merge with cities data\n",
    "snp500_with_population = pd.merge(snp500_data, cities_population_data, on=['city', 'state'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for NANs and fill them with population_data\n",
    "def fill_population(row):\n",
    "\tif pd.isna(row['population']):\n",
    "\t\t# Try to get the population from the county data\n",
    "\t\tcounty_population = counties_population_data[\n",
    "\t\t\t(counties_population_data['city'] == row['city']) &\n",
    "\t\t\t(counties_population_data['state'] == row['state'])\n",
    "\t\t\t]['population'].values\n",
    "\t\tif len(county_population) > 0:\n",
    "\t\t\treturn county_population[0]\n",
    "\t\t# If County data not found try Towns data\n",
    "\t\ttown_population = towns_population_data[\n",
    "\t\t\t(towns_population_data['city'] == row['city']) &\n",
    "\t\t\t(towns_population_data['state'] == row['state'])\n",
    "\t\t]['population'].values\n",
    "\t\tif len(town_population) > 0:\n",
    "\t\t\treturn town_population[0]\n",
    "\t\ttargeted_population = targeted_population_data[\n",
    "\t\t\t(targeted_population_data['city'] == row['city']) &\n",
    "\t\t\t(targeted_population_data['state'] == row['state'])\n",
    "\t\t\t]['population'].values\n",
    "\t\treturn targeted_population[0] if len(targeted_population) > 0 else None\n",
    "\treturn row['population']\n",
    "\n",
    "snp500_with_population['population'] = snp500_with_population.apply(fill_population, axis=1)\n",
    "\n",
    "path_to_save_csv = '../Group3Project1/Resources/snp500_with_population.csv'\n",
    "snp500_with_population.to_csv(path_to_save_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "#print(snp500_with_population.info())\n",
    "print(snp500_with_population['population'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating CSV with NAN population values rows removed\n",
    "snp500_no_nan_population = snp500_with_population.dropna(subset=['population'])\n",
    "\n",
    "snp500_no_nan_population_path = '../Group3Project1/Resources/snp500_no_nan_population.csv'\n",
    "snp500_no_nan_population.to_csv(snp500_no_nan_population_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
